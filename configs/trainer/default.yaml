rollout_steps: 256 # change later
rollout_iterations: 100
eval_frequency: 1
eval_episodes: 5
critic_epochs: 5
actor_epochs: 2
max_grad_norm: 0.5
critic_max_grad_norm: 4.0
tau: 0.1 # actual fn is 1-tau so our update is 0.9
critic_batch_size: 64   # this is per rank
actor_batch_size: 4   
num_workers: 1
gamma: 0.98
eval_instances: "instances_v1.6.json"
eval_rollout_steps: 36
warmup_iters: 1
scale_reward: True
scaling_factor: 100.00
is_replay_buffer: True
step_size: 256 # this number is global
inference_batch_size: 128 
actor_grad_accum_steps: 32 # this numberi s per rank
critic_grad_accum_steps: 2
buffer_size: 5120 # might be per rank, not sure
save_every: 5
# make sure that step size, grad accum and batch sizes add up.