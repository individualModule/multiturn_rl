2025-05-08 13:23:59,801 INFO    MainThread:13810 [wandb_setup.py:_flush():70] Current SDK version is 0.19.11
2025-05-08 13:23:59,801 INFO    MainThread:13810 [wandb_setup.py:_flush():70] Configure stats pid to 13810
2025-05-08 13:23:59,801 INFO    MainThread:13810 [wandb_setup.py:_flush():70] Loading settings from /root/.config/wandb/settings
2025-05-08 13:23:59,801 INFO    MainThread:13810 [wandb_setup.py:_flush():70] Loading settings from /root/workspace/thesisProject/multiturn_rl/wandb/settings
2025-05-08 13:23:59,801 INFO    MainThread:13810 [wandb_setup.py:_flush():70] Loading settings from environment variables
2025-05-08 13:23:59,801 INFO    MainThread:13810 [wandb_init.py:setup_run_log_directory():724] Logging user logs to /root/workspace/thesisProject/multiturn_rl/wandb/run-20250508_132359-jdswfo3g/logs/debug.log
2025-05-08 13:23:59,801 INFO    MainThread:13810 [wandb_init.py:setup_run_log_directory():725] Logging internal logs to /root/workspace/thesisProject/multiturn_rl/wandb/run-20250508_132359-jdswfo3g/logs/debug-internal.log
2025-05-08 13:23:59,802 INFO    MainThread:13810 [wandb_init.py:init():852] calling init triggers
2025-05-08 13:23:59,802 INFO    MainThread:13810 [wandb_init.py:init():857] wandb.init called with sweep_config: {}
config: {'trainer': {'rollout_steps': 32, 'rollout_iterations': 15, 'eval_frequency': 5, 'eval_episodes': 2, 'critic_epochs': 10, 'actor_epochs': 3, 'max_grad_norm': 0.5, 'tau': 0.005, 'batch_size': 32, 'num_workers': 4}, 'optimizer': {'actor': {'_target_': 'torch.optim.Adam', 'lr': 1e-06, 'betas': [0.9, 0.999]}, 'critic': {'_target_': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0.9, 0.999]}}, 'model': {'critic': {'hidden_dims': [512, 512], 'critic_lm': 'FacebookAI/roberta-base'}}, 'loss': {'actor': {'_target_': 'modelling.archer_critic.Reinforce'}, 'critic': {'_target_': 'modelling.archer_critic.TDLoss'}}, 'game': {'spec_name': 'guesswhat', 'teacher': {'model_name': 'Unsloth-Llama-3-8B', 'max_tokens': 300, 'temperature': 0.3}, 'learner': {'model_name': 'Unsloth-Llama-3-8B', 'max_tokens': 300, 'temperature': 0.3}}, 'project_name': 'archer-rl', 'seed': 42, 'device': 'cuda', '_wandb': {}}
2025-05-08 13:23:59,802 INFO    MainThread:13810 [wandb_init.py:init():893] starting backend
2025-05-08 13:23:59,802 INFO    MainThread:13810 [wandb_init.py:init():897] sending inform_init request
2025-05-08 13:23:59,807 INFO    MainThread:13810 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-05-08 13:23:59,807 INFO    MainThread:13810 [wandb_init.py:init():907] backend started and connected
2025-05-08 13:23:59,809 INFO    MainThread:13810 [wandb_init.py:init():1005] updated telemetry
2025-05-08 13:23:59,815 INFO    MainThread:13810 [wandb_init.py:init():1029] communicating run to backend with 90.0 second timeout
2025-05-08 13:24:00,470 INFO    MainThread:13810 [wandb_init.py:init():1104] starting run threads in backend
2025-05-08 13:24:00,619 INFO    MainThread:13810 [wandb_run.py:_console_start():2573] atexit reg
2025-05-08 13:24:00,619 INFO    MainThread:13810 [wandb_run.py:_redirect():2421] redirect: wrap_raw
2025-05-08 13:24:00,619 INFO    MainThread:13810 [wandb_run.py:_redirect():2490] Wrapping output streams.
2025-05-08 13:24:00,619 INFO    MainThread:13810 [wandb_run.py:_redirect():2513] Redirects installed.
2025-05-08 13:24:00,621 INFO    MainThread:13810 [wandb_init.py:init():1150] run started, returning control to user process
2025-05-08 13:24:00,659 INFO    MsgRouterThr:13810 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 2 handles.
